{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로를 이용해 LeNet-5 합성곱 아키텍처를 MNIST 데이터에 대해 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
    "WORK_DIRECTORY = 'data'\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10         # 10가지\n",
    "VALIDATION_SIZE = 5000  # size of the validation set\n",
    "SEED = 66478            # set to None for random seed\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_FREQUENCY = 100    # Number of steps between evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MNIST 데이터 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MNIST 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 집합을 다운로드하는 함수\n",
    "\n",
    "def download(filename) :\n",
    "    \n",
    "    # WORK_DIRECTORY가 존재하는지 확인\n",
    "    if not os.path.exists(WORK_DIRECTORY) :\n",
    "        os.makedirs(WORK_DIRECTORY)\n",
    "    \n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    print(filepath)\n",
    "    \n",
    "    if not os.path.exists(filepath) :\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        print(filepath)\n",
    "        size = os.stat(filepath).st_size\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'train-images-idx3-ubyte.gz'\n",
    "# filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "# print(filepath)\n",
    "# os.path.join(WORK_DIRECTORY, 'train-images-idx3-ubyte.gz')\n",
    "# 'data\\\\train-images-idx3-ubyte.gz'\n",
    "# print(SOURCE_URL + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드한 데이터 집합 이미지를 넘파이 배열로 추출\n",
    "\n",
    "def extract_data(filename, num_images) :\n",
    "    '''\n",
    "    이미지를 4차원 텐서[이미지 인덱스, y, x, 채널]로 추출한다.\n",
    "    값의 범위를 [0, 255]에서 [-0.5, 0.5]로 줄인다.\n",
    "    '''\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream :\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        # 원본 바이트 버퍼를 숫자 배열로 편리하게 변환\n",
    "        data = numpy.frombuffer(buf, dtype = numpy.uint8).astype(numpy.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드한 데이터 집합에서 레이블 배열로 추출\n",
    "# - 레이블은 문자열 바이트로 파일에 저장된다\n",
    "# - 8바이트로 된 헤더가 있고, 나머지 데이터는 레이블\n",
    "\n",
    "def extract_labels(filename, num_images) :\n",
    "    '''\n",
    "    int64형의 레이블 ID 벡터로 레이블을 추출한다.\n",
    "    '''\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream :\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype = numpy.uint8).astype(numpy.int64)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-images-idx3-ubyte.gz :  training set images (9912422 bytes)\n",
    "# train-labels-idx1-ubyte.gz :  training set labels (28881 bytes)\n",
    "# t10k-images-idx3-ubyte.gz :   test set images (1648877 bytes)\n",
    "# t10k-labels-idx1-ubyte.gz :   test set labels (4542 bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "data\\t10k-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 가져온다\n",
    "train_data_filename = download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = download('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 넘파이 배열로 추출한다\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000,), (10000, 28, 28, 1), (10000,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 집합은 하이퍼파라미터 튜닝을 위한 검증 데이터 집합을 명확히 정의 X\n",
    "# => 학습 데이터 집합의 최종 5000개 데이터를 검증 데이터로 수동 지정\n",
    "\n",
    "# 검증 집합 생성\n",
    "validation_data = train_data[:VALIDATION_SIZE, ...]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, ...]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 28, 28, 1), (5000,), (55000, 28, 28, 1), (55000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.shape, validation_labels.shape, train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = NUM_EPOCHS\n",
    "train_size = train_labels.shape[0] # 55000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아키텍처의 플레이스홀더 정의\n",
    "# - 학습할 이미지와 레이블을 입력할 두 개의 플레이스홀더 정의\n",
    "# - 이러한 특수 네트워크에서 커다란 배치 입력을 평가할 수 있도록 \n",
    "#   별도의 플레이스홀더 정의\n",
    "\n",
    "train_data_node = tf.placeholder(tf.float32, \n",
    "                                 shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, \n",
    "                                  shape = (BATCH_SIZE, ))\n",
    "eval_data = tf.placeholder(tf.float32, \n",
    "                           shape = (EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 텐서플로 합성곱 기본 요소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로에서 2차원 합성곱 정의\n",
    "# tf.nn.conv2d 함수는 텐서플로 내장 함수이며 합성곱 계층을 정의\n",
    "tf.nn.conv2d(\n",
    "    input,     # 텐서 형상(batch, height, width, channels)\n",
    "    filter,    # 텐서 형상(filter_height, filter_width, channels, out_channels) \n",
    "               #  : 합성곱 커널에서 학습되는 비선형 변환의 학습 가능한 가중치 \n",
    "    strides,   # 필터 스트라이드, 길이 4의 배열(입력 차원마다 하나)\n",
    "    padding,   # 입력 텐서에 여백을 넣는 것, \"SAME\" / \"VALID\"\n",
    "    use_cudnn_on_gpu = None,\n",
    "    data_format = None,\n",
    "    name = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로에서 최대 풀링 정의\n",
    "# tf.nn.max_pool 함수는 최대 풀링을 수행\n",
    "tf.nn.max_pool(\n",
    "    value,    # 텐서 형상(batch, height, width, channels)\n",
    "    ksize,    # 풀링 창의 크기, 길이 4의 리스트\n",
    "    strides,\n",
    "    padding,\n",
    "    data_format='NHWC',\n",
    "    name = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 합성곱 아키텍처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 아키텍처 정의\n",
    "# : 합성곱 - 풀링 - 합성곱 - 풀링 - 완전연결 - 완전연결 (6개 계층)\n",
    "\n",
    "def model(data, train=False) :\n",
    "    \n",
    "    # 'SAME' 패딩을 적용한 2D 합성곱(출력 피처 맵은 입력과 동일한 크기)\n",
    "    # {strides}는 4D 배열이며,\n",
    "    # 형상은 데이터 레이아웃과 동일한 [이미지 인덱스, y, x, 깊이]\n",
    "    conv = tf.nn.conv2d(data, conv1_weights, strides=[1, 1, 1, 1], padding = 'SAME')\n",
    "    # 편향과 렐루\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "    \n",
    "    # 최대 풀링\n",
    "    # 커널 크기 {ksize}는 데이터 레이아웃과 동일\n",
    "    # 풀링 창은 2이고, 스트라이드는 2\n",
    "    pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, conv2_weights, strides=[1, 1, 1, 1], padding = 'SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    # 직육면체 피처 맵을 2D 행렬로 변형한 다음 완전연결 계층에 전달\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    print('pool_shape : ', pool_shape)\n",
    "    reshape = tf.reshape(pool, [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "    \n",
    "    # 완전연결 계층\n",
    "    # '+' 연산은 자동으로 편향에 브로드캐스트\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "    \n",
    "    # 학습 중에만 50% 드롭아웃을 추가\n",
    "    # 또 드롭아웃은 평가 시점에 조절이 필요 없도록 활성화 정도를 조절\n",
    "    if train :\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed = SEED)\n",
    "        \n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 계층을 위한 학습 가능한 가중치 정의\n",
    "\n",
    "conv1_weights = tf.Variable( tf.truncated_normal([5, 5, NUM_CHANNELS, 32], # 5x5 필터, 깊이 32 \n",
    "                                                 stddev = 0.1, \n",
    "                                                 seed = SEED, \n",
    "                                                 dtype = tf.float32) )\n",
    "conv1_biases = tf.Variable(tf.zeros([32], dtype=tf.float32))\n",
    "\n",
    "conv2_weights = tf.Variable( tf.truncated_normal([5, 5, 32, 64], \n",
    "                                                 stddev = 0.1, \n",
    "                                                 seed = SEED, \n",
    "                                                 dtype = tf.float32) )\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전연결 계층을 위한 학습 가능한 가중치 정의\n",
    "\n",
    "fc1_weights = tf.Variable( # 완전 연결, 깊이 512\n",
    "    tf.truncated_normal([IMAGE_SIZE//4 * IMAGE_SIZE//4 * 64, 512],\n",
    "                                                 stddev = 0.1, \n",
    "                                                 seed = SEED, \n",
    "                                                 dtype = tf.float32) )\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512], dtype=tf.float32))\n",
    "\n",
    "fc2_weights = tf.Variable( tf.truncated_normal([512, NUM_LABELS], \n",
    "                                                 stddev = 0.1, \n",
    "                                                 seed = SEED, \n",
    "                                                 dtype = tf.float32) )\n",
    "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training computation : logits + cross_entropy loss\n",
    "logits = model(train_data_node, True)\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels = train_labels_node, logits = logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization for the fully connected parameters\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights)\n",
    "               + tf.nn.l2_loss(fc1_biases)\n",
    "               + tf.nn.l2_loss(fc2_weights)\n",
    "               + tf.nn.l2_loss(fc2_biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the regularization term to the loss\n",
    "loss += 5e-4 * regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer :\n",
    "# set up a variable \n",
    "# that's incremented once per batch and controls the learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 아키텍처 학습\n",
    "\n",
    "# 학습을 수행하기 위해 지역 세션을 생성\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    \n",
    "    # 모든 initializers를 실행해 학습 가능한 매개변수 준비\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # 학습 단계 순환\n",
    "    for step in xrange(int(num_epochs * train_size) // BATCH_SIZE) :\n",
    "        \n",
    "        # 데이터에서 현재 미니배치의 오프셋 계산\n",
    "        # 에폭마다 더 나은 무작위 추출을 사용할 수도 있다\n",
    "        offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "        batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "        batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "        \n",
    "        feed_dict = {\n",
    "            train_data_node : batch_data,\n",
    "            train_labels_node : batch_labels\n",
    "        }\n",
    "        \n",
    "        # Run the optimizer to update weights\n",
    "        sess.run(optimizer, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
